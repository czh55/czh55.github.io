<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.chenzhiheng.cn","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="陈志恒的技术博客">
<meta property="og:url" content="http://www.chenzhiheng.cn/page/47/index.html">
<meta property="og:site_name" content="陈志恒的技术博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zhiheng Chen">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://www.chenzhiheng.cn/page/47/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>陈志恒的技术博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6bc779d0e3be483fc01e871fbb7cef3d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">陈志恒的技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2015]Trajectory%20Triangulation+NRSFM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2015%5DTrajectory%20Triangulation+NRSFM/" class="post-title-link" itemprop="url">2015Trajectory Triangulation+NRSFM</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-04 12:54:00" itemprop="dateCreated datePublished" datetime="2019-03-04T12:54:00+08:00">2019-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2015%5DTrajectory%20Triangulation+NRSFM/" class="post-meta-item leancloud_visitors" data-flag-title="2015Trajectory Triangulation+NRSFM" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年3月4日 下午12:54</p>
<p>[2015]3D Trajectory Reconstruction under Perspective Projection</p>
<h2 id="这篇文章："><a href="#这篇文章：" class="headerlink" title="这篇文章："></a>这篇文章：</h2><ol>
<li><p>We demonstrate its application in reconstructing moving points from a series of image projections where <strong>no two image</strong> projections necessarily occur at the <strong>same time instant</strong>.</p>
</li>
<li><p>Trajectory Triangulation</p>
<ol>
<li>Longuet-Higgins, H. C. (1981). A computer algorithm for reconstructing a scene from two projections.<em>Nature</em>,<em>293</em>, 133–135.   <a href="https://doi.org/10.1038/293133a0" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=A%20computer%20algorithm%20for%20reconstructing%20a%20scene%20from%20two%20projections&author=HC.%20Longuet-Higgins&journal=Nature&volume=293&pages=133-135&publication_year=1981" target="_blank" rel="noopener">Google Scholar</a> <ol>
<li>发展：    <ol>
<li>*Faugeras, O., Luong, Q.-T., &amp; Papadopoulou, T. (2001).<em>The geometry of multiple images: The laws that govern the formation of images of a scene and some of their applications</em>. Cambridge: MIT Press. <a href="http://scholar.google.com/scholar_lookup?title=The%20geometry%20of%20multiple%20images%3A%20The%20laws%20that%20govern%20the%20formation%20of%20images%20of%20a%20scene%20and%20some%20of%20their%20applications&author=O.%20Faugeras&author=Q-T.%20Luong&author=T.%20Papadopoulou&publication_year=2001" target="_blank" rel="noopener">Google Scholar</a> </li>
<li><ul>
<li>Ma, Y., Soatto, S., Kosecka, J., &amp; Sastry, S. S. (2003).<em>An invitation to 3-D vision: From images to geometric models</em>. New York: Springer. <a href="http://scholar.google.com/scholar_lookup?title=An%20invitation%20to%203-D%20vision%3A%20From%20images%20to%20geometric%20models&author=Y.%20Ma&author=S.%20Soatto&author=J.%20Kosecka&author=SS.%20Sastry&publication_year=2003" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Hartley, 照亮., &amp; Zisserman, A. (2004).<em>Multiple view geometry in computer vision</em>(2nd ed.). Cambridge: Cambridge University Press.     <a href="http://www.emis.de/MATH-item?1072.68104" target="_blank" rel="noopener">zbMATH</a>  <a href="https://doi.org/10.1017/CBO9780511811685" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Multiple%20view%20geometry%20in%20computer%20vision&author=R.%20Hartley&author=A.%20Zisserman&publication_year=2004" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li><ul>
<li>Avidan, S., &amp; Shashua, A. (2000). <strong>Trajectory triangulation</strong>: 3D reconstruction of moving points from a monocular image sequence.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>22</em>, 348–357.   <a href="https://doi.org/10.1109/34.845377" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Trajectory%20triangulation%3A%203D%20reconstruction%20of%20moving%20points%20from%20a%20monocular%20image%20sequence&author=S.%20Avidan&author=A.%20Shashua&journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&volume=22&pages=348-357&publication_year=2000" target="_blank" rel="noopener">Google Scholar</a> <ol>
<li>introduced homography tensors to represent a point <strong>moving on the plane</strong><ol>
<li><ul>
<li>Shashua, A., &amp; Wolf, L. (2000). Homography tensors: On algebraic entities that represent three views of static or moving planar points. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Shashua%2C%20A.%2C%20%26%20Wolf%2C%20L.%20%282000%29.%20Homography%20tensors%3A%20On%20algebraic%20entities%20that%20represent%20three%20views%20of%20static%20or%20moving%20planar%20points.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Wexler, Y., &amp; Shashua, A. (2000). On the synthesis of dynamic scenes from reference views. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Wexler%2C%20Y.%2C%20%26%20Shashua%2C%20A.%20%282000%29.%20On%20the%20synthesis%20of%20dynamic%20scenes%20from%20reference%20views.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>As an integration of the algebraic curve representation<ol>
<li><ul>
<li>Wolf, L., &amp; Shashua, A. (2002). On projection matricesPk→P2,k=3,…, 6, and their applications in computer vision.<em>International Journal of Computer Vision</em>,<em>48</em>(1), 53–67.     <a href="http://www.emis.de/MATH-item?1012.68749" target="_blank" rel="noopener">zbMATH</a>  <a href="https://doi.org/10.1023/A%3A1014855311993" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=On%20projection%20matrices%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%24%24%7B%5Ccal%20P%7D%5E%7Bk%7D%20%5Crightarrow%20%7B%5Ccal%20P%7D%5E%7B2%7D%2C%20k%20%3D3%2C%20%5Cldots%20%24%24%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20P%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20k%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%92%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20P%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%202%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20k%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%203%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%80%A6%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2C%206%2C%20and%20their%20applications%20in%20computer%20vision&author=L.%20Wolf&author=A.%20Shashua&journal=International%20Journal%20of%20Computer%20Vision&volume=48&issue=1&pages=53-67&publication_year=2002" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>hypersurfaces<ol>
<li><ul>
<li>Kaminski, J. Y., &amp; Teicher, M. (2004). A general framework for trajectory triangulation.<em>Journal of Mathematical Imaging and Vision</em>,<em>21</em>(1), 27–41.     <a href="http://www.ams.org/mathscinet-getitem?mr=2075715" target="_blank" rel="noopener">MathSciNet</a>  <a href="https://doi.org/10.1023/B%3AJMIV.0000026555.79056.b8" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=A%20general%20framework%20for%20trajectory%20triangulation&author=JY.%20Kaminski&author=M.%20Teicher&journal=Journal%20of%20Mathematical%20Imaging%20and%20Vision&volume=21&issue=1&pages=27-41&publication_year=2004" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ol>
<p>NRSFM</p>
<ol>
<li>They formulated the problem as a <strong>trilinear optimization</strong> over camera motion, shape basis vectors, and shape coefﬁcient vectors<ol>
<li>linear shape models as a representation<ol>
<li><ul>
<li>Bregler, C., Hertzmann, A., &amp; Biermann, H. (1999). Recovering non-rigid 3D shape from image streams. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Bregler%2C%20C.%2C%20Hertzmann%2C%20A.%2C%20%26%20Biermann%2C%20H.%20%281999%29.%20Recovering%20non-rigid%203D%20shape%20from%20image%20streams.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> <ol>
<li>基于：<ol>
<li><ul>
<li>Tomasi, C., &amp; Kanade, T. (1992). Shape and motion from image streams under orthography: A factorization method.<em>International Journal of Computer Vision</em>,<em>9</em>(2), 137–154.   <a href="https://doi.org/10.1007/BF00129684" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Shape%20and%20motion%20from%20image%20streams%20under%20orthography%3A%20A%20factorization%20method&author=C.%20Tomasi&author=T.%20Kanade&journal=International%20Journal%20of%20Computer%20Vision&volume=9&issue=2&pages=137-154&publication_year=1992" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li>被non-convexity(非凸性)困扰<ol>
<li><ul>
<li>Brand, M. (2005). A direct method for 3D factorization of nonrigid motion observed in 2D. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Brand%2C%20M.%20%282005%29.%20A%20direct%20method%20for%203D%20factorization%20of%20nonrigid%20motion%20observed%20in%202D.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a></li>
</ul>
</li>
<li><ul>
<li>Xiao, J., &amp; Kanade, T. (2004). Non-rigid shape and motion recovery: Degenerate deformations. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Xiao%2C%20J.%2C%20%26%20Kanade%2C%20T.%20%282004%29.%20Non-rigid%20shape%20and%20motion%20recovery%3A%20Degenerate%20deformations.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a>  </li>
</ul>
</li>
<li><ul>
<li>Xiao, J., Chai, J., &amp; Kanade, T. (2006). A closed-form solution to non-rigid shape and motion recovery.<em>International Journal of Computer Vision</em>,<em>67</em>(2), 233–246.   <a href="https://doi.org/10.1007/s11263-005-3962-9" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=A%20closed-form%20solution%20to%20non-rigid%20shape%20and%20motion%20recovery&author=J.%20Xiao&author=J.%20Chai&author=T.%20Kanade&journal=International%20Journal%20of%20Computer%20Vision&volume=67&issue=2&pages=233-246&publication_year=2006" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Akhter, I., Sheikh, Y., &amp; Khan, S. (2009). In defense of orthonormality constraints for nonrigid structure from motion. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Akhter%2C%20I.%2C%20Sheikh%2C%20Y.%2C%20%26%20Khan%2C%20S.%20%282009%29.%20In%20defense%20of%20orthonormality%20constraints%20for%20nonrigid%20structure%20from%20motion.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>used an alternating linear least squares technique<ol>
<li><ul>
<li>Torresani, L., Yang, D., Alexander, G., &amp; Bregler, C. (2001). Tracking and modeling non-rigid objects with rank constraints. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Torresani%2C%20L.%2C%20Yang%2C%20D.%2C%20Alexander%2C%20G.%2C%20%26%20Bregler%2C%20C.%20%282001%29.%20Tracking%20and%20modeling%20non-rigid%20objects%20with%20rank%20constraints.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Torresani, L., Hertzmann, A., &amp; Bregler, C. (2008). Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>30</em>, 878–892. <a href="https://scholar.google.com/scholar?q=Torresani%2C%20L.%2C%20Hertzmann%2C%20A.%2C%20%26%20Bregler%2C%20C.%20%282008%29.%20Nonrigid%20structure-from-motion%3A%20Estimating%20shape%20and%20motion%20with%20hierarchical%20priors.%20IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence%2C%2030%2C%20878%E2%80%93892." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>sophisticated initialization<ol>
<li><ul>
<li>Brand, M. (2001). Morphable 3D models from video. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Brand%2C%20M.%20%282001%29.%20Morphable%203D%20models%20from%20video.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>a robust metric upgrade method<ol>
<li><ul>
<li>Paladini, M., Del Bue, A., Stosic, M., Dodig, M., Xavier, J., &amp; Agapito, L. (2009). Factorization for non-rigid and articulated structure using metric projections. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Paladini%2C%20M.%2C%20Del%20Bue%2C%20A.%2C%20Stosic%2C%20M.%2C%20Dodig%2C%20M.%2C%20Xavier%2C%20J.%2C%20%26%20Agapito%2C%20L.%20%282009%29.%20Factorization%20for%20non-rigid%20and%20articulated%20structure%20using%20metric%20projections.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li><strong>Prior knowledge</strong> on shapes that regularizes deformation can improve stability of the optimization<ol>
<li>added a shape basis constraint<ol>
<li><ol start="2">
<li><ul>
<li>Xiao, J., &amp; Kanade, T. (2004). Non-rigid shape and motion recovery: Degenerate deformations. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Xiao%2C%20J.%2C%20%26%20Kanade%2C%20T.%20%282004%29.%20Non-rigid%20shape%20and%20motion%20recovery%3A%20Degenerate%20deformations.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a>  </li>
</ul>
</li>
</ol>
</li>
<li><ul>
<li>Xiao, J., Chai, J., &amp; Kanade, T. (2006). A closed-form solution to non-rigid shape and motion recovery.<em>International Journal of Computer Vision</em>,<em>67</em>(2), 233–246.   <a href="https://doi.org/10.1007/s11263-005-3962-9" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=A%20closed-form%20solution%20to%20non-rigid%20shape%20and%20motion%20recovery&author=J.%20Xiao&author=J.%20Chai&author=T.%20Kanade&journal=International%20Journal%20of%20Computer%20Vision&volume=67&issue=2&pages=233-246&publication_year=2006" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li><ul>
<li>Torresani, L., &amp; Bregler, C. (2002). Space-time tracking. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Torresani%2C%20L.%2C%20%26%20Bregler%2C%20C.%20%282002%29.%20Space-time%20tracking.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Torresani, L., Hertzmann, A., &amp; Bregler, C. (2003). Learning non-rigid 3D shape from 2D motion. In_Advances in Neural Information Processing Systems_. <a href="https://scholar.google.com/scholar?q=Torresani%2C%20L.%2C%20Hertzmann%2C%20A.%2C%20%26%20Bregler%2C%20C.%20%282003%29.%20Learning%20non-rigid%203D%20shape%20from%202D%20motion.%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Olsen, S., &amp; Bartoli, A. (2007). Using priors for improving generalization in non-rigid structure-from-motion. In_Proceedings of British Machine Vision Conference_. <a href="https://scholar.google.com/scholar?q=Olsen%2C%20S.%2C%20%26%20Bartoli%2C%20A.%20%282007%29.%20Using%20priors%20for%20improving%20generalization%20in%20non-rigid%20structure-from-motion.%20In%20Proceedings%20of%20British%20Machine%20Vision%20Conference." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Yan, J., &amp; Pollefeys, M. (2005). A factorization-based approach to articulated motion recovery. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Yan%2C%20J.%2C%20%26%20Pollefeys%2C%20M.%20%282005%29.%20A%20factorization-based%20approach%20to%20articulated%20motion%20recovery.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Del Bue, A. (2008). A factorization approach to structure from motion with shape priors. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Del%20Bue%2C%20A.%20%282008%29.%20A%20factorization%20approach%20to%20structure%20from%20motion%20with%20shape%20priors.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Fayad, J., Agapito, L., &amp; Del Bue, A. (2010). Piecewise quadratic reconstruction of non-rigid surface from monocular sequences. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Fayad%2C%20J.%2C%20Agapito%2C%20L.%2C%20%26%20Del%20Bue%2C%20A.%20%282010%29.%20Piecewise%20quadratic%20reconstruction%20of%20non-rigid%20surface%20from%20monocular%20sequences.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>引入的其他问题：<ol>
<li>A nonrigid structure <strong>registration</strong><ol>
<li><ul>
<li>Blanz, V., &amp; Vetter, T. (1999). A morphable model for the synthesis of 3D faces. In_ACM transactions on Graphics (SIGGRAPH)_. <a href="https://scholar.google.com/scholar?q=Blanz%2C%20V.%2C%20%26%20Vetter%2C%20T.%20%281999%29.%20A%20morphable%20model%20for%20the%20synthesis%20of%203D%20faces.%20In%20ACM%20transactions%20on%20Graphics%20%28SIGGRAPH%29." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li>A <strong>surface</strong> is another target structure<ol>
<li><ul>
<li>Salzmann, M., Pilet, J., Ilic, S., &amp; Fua, P. (2007). Surface deformation models for nonrigid 3D shape recovery.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>29</em>(7), 1481–1487.   <a href="https://doi.org/10.1109/TPAMI.2007.1080" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Surface%20deformation%20models%20for%20nonrigid%203D%20shape%20recovery&author=M.%20Salzmann&author=J.%20Pilet&author=S.%20Ilic&author=P.%20Fua&journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&volume=29&issue=7&pages=1481-1487&publication_year=2007" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Taylor, J., Jepson, A. D., &amp; Kutulakos, K. N. (2010). Non-rigid structure from locally-rigid motion. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Taylor%2C%20J.%2C%20Jepson%2C%20A.%20D.%2C%20%26%20Kutulakos%2C%20K.%20N.%20%282010%29.%20Non-rigid%20structure%20from%20locally-rigid%20motion.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li><ul>
<li>Östlund, J., Varol, A., Ngo, D. T., &amp; Fua, P. (2012). Laplacian meshes for monocular 3D shape recovery. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=%C3%96stlund%2C%20J.%2C%20Varol%2C%20A.%2C%20Ngo%2C%20D.%20T.%2C%20%26%20Fua%2C%20P.%20%282012%29.%20Laplacian%20meshes%20for%20monocular%203D%20shape%20recovery.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li>modeled each trajectory using a linear combination of <strong>trajectory basis</strong> vectors<ol>
<li><ul>
<li>Sidenbladh, H., Black, M. J., &amp; Fleet, D. J. (2000). Stochastic tracking of 3d human figures using 2D image motion. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Sidenbladh%2C%20H.%2C%20Black%2C%20M.%20J.%2C%20%26%20Fleet%2C%20D.%20J.%20%282000%29.%20Stochastic%20tracking%20of%203d%20human%20figures%20using%202D%20image%20motion.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li>DCT<ol>
<li><ul>
<li>Akhter, I., Sheikh, Y., Khan, S., &amp; Kanade, T. (2008). Nonrigid structure from motion in trajectory space. In_Advances in Neural Information Processing Systems_. <a href="https://scholar.google.com/scholar?q=Akhter%2C%20I.%2C%20Sheikh%2C%20Y.%2C%20Khan%2C%20S.%2C%20%26%20Kanade%2C%20T.%20%282008%29.%20Nonrigid%20structure%20from%20motion%20in%20trajectory%20space.%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
<li>Akhter, I., Sheikh, Y., Khan, S., &amp; Kanade, T. (2011). Trajectory space: A dual representation for nonrigid structure from motion.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>33</em>(7), 1442–1456.   <a href="https://doi.org/10.1109/TPAMI.2010.201" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Trajectory%20space%3A%20A%20dual%20representation%20for%20nonrigid%20structure%20from%20motion&author=I.%20Akhter&author=Y.%20Sheikh&author=S.%20Khan&author=T.%20Kanade&journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&volume=33&issue=7&pages=1442-1456&publication_year=2011" target="_blank" rel="noopener">Google Scholar</a> </li>
<li><ul>
<li>Gotardo, P. F. U., &amp; Martinez, A. M. (2011). Computing smooth time-trajectories for camera and deformable shape in structure from motion with occlusion.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>33</em>(10), 2051–2065.   <a href="https://doi.org/10.1109/TPAMI.2011.50" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Computing%20smooth%20time-trajectories%20for%20camera%20and%20deformable%20shape%20in%20structure%20from%20motion%20with%20occlusion&author=PFU.%20Gotardo&author=AM.%20Martinez&journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&volume=33&issue=10&pages=2051-2065&publication_year=2011" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
<li><ul>
<li>Valmadre, J., &amp; Lucey, S. (2012). General trajectory prior for non-rigid reconstruction. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Valmadre%2C%20J.%2C%20%26%20Lucey%2C%20S.%20%282012%29.%20General%20trajectory%20prior%20for%20non-rigid%20reconstruction.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><p>Bartoli, A., Gay-Bellile, V., Castellani, U., Peyras, J., Olsen, S. I., &amp; Sayd, P. (2008). Coarse-to-fine low-rank structure-from-motion. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Bartoli%2C%20A.%2C%20Gay-Bellile%2C%20V.%2C%20Castellani%2C%20U.%2C%20Peyras%2C%20J.%2C%20Olsen%2C%20S.%20I.%2C%20%26%20Sayd%2C%20P.%20%282008%29.%20Coarse-to-fine%20low-rank%20structure-from-motion.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Dai, Y., Li, H., &amp; He, M. (2012). A simple prior-free method for non-rigid structure-from-motion factorization. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Dai%2C%20Y.%2C%20Li%2C%20H.%2C%20%26%20He%2C%20M.%20%282012%29.%20A%20simple%20prior-free%20method%20for%20non-rigid%20structure-from-motion%20factorization.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Del Bue, A., Llad, X., &amp; Agapito, L. (2006). Non-rigid metric shape and motion recovery from uncalibrated images using priors. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Del%20Bue%2C%20A.%2C%20Llad%2C%20X.%2C%20%26%20Agapito%2C%20L.%20%282006%29.%20Non-rigid%20metric%20shape%20and%20motion%20recovery%20from%20uncalibrated%20images%20using%20priors.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
</ul>
<ul>
<li>Fischler, M. A., &amp; Bolles, 照亮. C. (1981). Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography.<em>Communications of the ACM</em>,<em>24</em>(6), 381–395.     <a href="http://www.ams.org/mathscinet-getitem?mr=618158" target="_blank" rel="noopener">MathSciNet</a>  <a href="https://doi.org/10.1145/358669.358692" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Random%20sample%20consensus%3A%20A%20paradigm%20for%20model%20fitting%20with%20applications%20to%20image%20analysis%20and%20automated%20cartography&author=MA.%20Fischler&author=RC.%20Bolles&journal=Communications%20of%20the%20ACM&volume=24&issue=6&pages=381-395&publication_year=1981" target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
<ul>
<li><p>Hamidi, M., &amp; Pearl, J. (1976). Comparison of the cosine and Fourier transforms of Markov-I signal.<em>IEEE Transactions on Acoustics, Speech, and Signal Processing</em>,<em>24</em>, 428–429.     <a href="http://www.ams.org/mathscinet-getitem?mr=429337" target="_blank" rel="noopener">MathSciNet</a>  <a href="https://doi.org/10.1109/TASSP.1976.1162839" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Comparison%20of%20the%20cosine%20and%20Fourier%20transforms%20of%20Markov-I%20signal&author=M.%20Hamidi&author=J.%20Pearl&journal=IEEE%20Transactions%20on%20Acoustics%2C%20Speech%2C%20and%20Signal%20Processing&volume=24&pages=428-429&publication_year=1976" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Hartley, 照亮. (1997). In defense of the eight-point algorithm.<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,<em>19</em>, 580–593.   <a href="https://doi.org/10.1109/34.601246" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=In%20defense%20of%20the%20eight-point%20algorithm&author=R.%20Hartley&journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&volume=19&pages=580-593&publication_year=1997" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Hartley, 照亮., &amp; Vidal, 照亮. (2008). Perspective nonrigid shape and motion recovery. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Hartley%2C%20R.%2C%20%26%20Vidal%2C%20R.%20%282008%29.%20Perspective%20nonrigid%20shape%20and%20motion%20recovery.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Lladó, X., Del Bue, A., &amp; Agapito, L. (2010). Non-rigid metric reconstruction from perspective cameras.<em>Image and Vision Computing</em>,<em>28</em>(9), 1339–1353.   <a href="https://doi.org/10.1016/j.imavis.2010.01.014" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Non-rigid%20metric%20reconstruction%20from%20perspective%20cameras&author=X.%20Llad%C3%B3&author=A.%20Bue&author=L.%20Agapito&journal=Image%20and%20Vision%20Computing&volume=28&issue=9&pages=1339-1353&publication_year=2010" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Lourakis, M. I. A., &amp; Argyros, A. A. (2009). SBA: A software package for generic sparse bundle adjustment.<em>ACM Transactions on Mathematical Software</em>,<em>36</em>(1), 1–30.     <a href="http://www.ams.org/mathscinet-getitem?mr=2738183" target="_blank" rel="noopener">MathSciNet</a>  <a href="https://doi.org/10.1145/1486525.1486527" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=SBA%3A%20A%20software%20package%20for%20generic%20sparse%20bundle%20adjustment&author=MIA.%20Lourakis&author=AA.%20Argyros&journal=ACM%20Transactions%20on%20Mathematical%20Software&volume=36&issue=1&pages=1-30&publication_year=2009" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Lowe, D. G. (2004). Distinctive image features from scale-invariant keypoints.<em>International Journal of Computer Vision</em>,<em>60</em>(2), 91–110.   <a href="https://doi.org/10.1023/B%3AVISI.0000029664.99615.94" target="_blank" rel="noopener">CrossRef</a>  <a href="http://scholar.google.com/scholar_lookup?title=Distinctive%20image%20features%20from%20scale-invariant%20keypoints&author=DG.%20Lowe&journal=International%20Journal%20of%20Computer%20Vision&volume=60&issue=2&pages=91-110&publication_year=2004" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Moreno-Noguer, F., Lepetit, V., &amp; Fua, P. (2007). EPnP: Efficient perspective-n-point camera pose estimation. In_Proceedings of the International Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Moreno-Noguer%2C%20F.%2C%20Lepetit%2C%20V.%2C%20%26%20Fua%2C%20P.%20%282007%29.%20EPnP%3A%20Efficient%20perspective-n-point%20camera%20pose%20estimation.%20In%20Proceedings%20of%20the%20International%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Ozden, K. E., Cornelis, K., Eychen, L. V., &amp; Gool, L. V. (2004). Reconstructing 3D trajectories of independently moving objects using generic constraints.<em>Computer Vision and Image Understanding</em>,<em>93</em>, 1453–1471. <a href="http://scholar.google.com/scholar_lookup?title=Reconstructing%203D%20trajectories%20of%20independently%20moving%20objects%20using%20generic%20constraints&author=KE.%20Ozden&author=K.%20Cornelis&author=LV.%20Eychen&author=LV.%20Gool&journal=Computer%20Vision%20and%20Image%20Understanding&volume=93&pages=1453-1471&publication_year=2004" target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Park, H. S., Shiratori, T., Matthews, I., &amp; Sheikh, Y. (2010). 3D reconstruction of a moving point from a series of 2D projections. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Park%2C%20H.%20S.%2C%20Shiratori%2C%20T.%2C%20Matthews%2C%20I.%2C%20%26%20Sheikh%2C%20Y.%20%282010%29.%203D%20reconstruction%20of%20a%20moving%20point%20from%20a%20series%20of%202D%20projections.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Snavely, N., Seitz, S. M., &amp; Szeliski, 照亮. (2006). Photo tourism: Exploring photo collections in 3D.<em>ACM Transactions on Graphics (SIGGRAPH)</em>. <a href="https://scholar.google.com/scholar?q=Snavely%2C%20N.%2C%20Seitz%2C%20S.%20M.%2C%20%26%20Szeliski%2C%20R.%20%282006%29.%20Photo%20tourism%3A%20Exploring%20photo%20collections%20in%203D.%20ACM%20Transactions%20on%20Graphics%20%28SIGGRAPH%29." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
</ul>
<ul>
<li>Vidal, 照亮., &amp; Abretske, D. (2006). Nonrigid shape and motion from multiple perspective views. In_Proceedings of the European Conference on Computer Vision_. <a href="https://scholar.google.com/scholar?q=Vidal%2C%20R.%2C%20%26%20Abretske%2C%20D.%20%282006%29.%20Nonrigid%20shape%20and%20motion%20from%20multiple%20perspective%20views.%20In%20Proceedings%20of%20the%20European%20Conference%20on%20Computer%20Vision." target="_blank" rel="noopener">Google Scholar</a> </li>
</ul>
<ul>
<li><p>Vidal, 照亮., &amp; Hartley, 照亮. (2004). Motion segmentation with missing data by powerfactorization and generalized pca. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Vidal%2C%20R.%2C%20%26%20Hartley%2C%20R.%20%282004%29.%20Motion%20segmentation%20with%20missing%20data%20by%20powerfactorization%20and%20generalized%20pca.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
<li><p>Zhu, S., Zhang, L., &amp; Smith, B. M. (2010). Model evolution: An incremental approach to non-rigid structure from motion. In_Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. <a href="https://scholar.google.com/scholar?q=Zhu%2C%20S.%2C%20Zhang%2C%20L.%2C%20%26%20Smith%2C%20B.%20M.%20%282010%29.%20Model%20evolution%3A%20An%20incremental%20approach%20to%20non-rigid%20structure%20from%20motion.%20In%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition." target="_blank" rel="noopener">Google Scholar</a> </p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2018]SaMfM(trajectory%20triangulation)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2018%5DSaMfM(trajectory%20triangulation)/" class="post-title-link" itemprop="url">2018SaMfM(trajectory triangulation)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-04 11:52:00" itemprop="dateCreated datePublished" datetime="2019-03-04T11:52:00+08:00">2019-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2018%5DSaMfM(trajectory%20triangulation)/" class="post-meta-item leancloud_visitors" data-flag-title="2018SaMfM(trajectory triangulation)" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年3月4日 上午11:52</p>
<p>Velocity and Path Reconstruction of a Moving Object Using a Moving Camera</p>
<ol>
<li><p>Known <strong>Euclidean distances</strong> between feature points, or multiple <strong>simultaneous views</strong> of a object may be used (cf., [1], [2]) to <strong>determine scale</strong></p>
<ol>
<li>[1] R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision. Cambridge University Press, 2003.</li>
<li>[2] Y. Ma, S. Soatto, J. Kosecka, and S. Sastry, An Invitation to 3-D Vision.</li>
</ol>
</li>
<li><p>the <strong>motion of the camera</strong> is used to <strong>determine scale information</strong> of stationary features which may then be used to <strong>estimate the camera trajectory</strong></p>
<ol>
<li>[3] L. Matthies, T. Kanade, and R. Szeliski, “Kalman ﬁlter-based algorithm for <strong>estimating dept</strong>h from image sequences,” Int. J. Comput. Vision, vol. 3, pp. 209–236, 1989.</li>
<li>[4] A. Dani, N. Fischer, Z. Kan, and W. E. Dixon, “Globally exponentially stable observer for vision-based <strong>range estimation</strong>,” Mechatron., vol. 22, no. 4, pp. 381–389, Special Issue on Visual Servoing 2012.</li>
<li>[5] Z. I. Bell, H.-Y. Chen, A. Parikh, and W. E. Dixon, “Single scene and path reconstruction with a monocular camera using integral concurrent learning,” in Proc. IEEE Conf. Decis. Control, 2017, pp. 3670–3675.</li>
</ol>
</li>
</ol>
<ol>
<li>structure and motion from motion (<strong>SaMfM</strong>) <strong>problem:trajectory triangulation</strong><ol>
<li>起始：<ol>
<li>[7] S. Avidan and A. Shashua, “<strong>Trajectory triangulation</strong>: 3D reconstruction of moving points from a monocular image sequence,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 4, pp. 348–357, Apr. 2000.</li>
<li>[8] J. Kaminski and M. Teicher, “A general framework for <strong>trajectory triangulation</strong>,” J. Math. Imag. Vis., vol. 21, no. 1, pp. 27–41, 2004.</li>
<li>[9] A. Bartoli and P. Sturm, “Structure-from-motion using lines: Representation, triangulation, and bundle adjustment,” Comput. Vis. Image. Understand., vol. 100, no. 3, pp. 416–441, 2005.</li>
<li>[10] A. Bartoli, “The <strong>geometry</strong> of dynamic scenes – on coplanar and convergent linear motions embedded in 3D static scenes,” Comput. Vis. Image. Understand., vol. 98, no. 2, pp. 223–238, 2005.</li>
</ol>
</li>
<li>[6] A. Dani, Z. Kan, N. Fischer, and W. E. Dixon, “Structure and motion estimation of a moving object using a moving camera,” in Proc. Am. Control Conf., Baltimore, MD, 2010, pp. 6962–6967.<ol>
<li>评价：a robust integral sign of the error (<strong>RISE</strong>) <strong>observer</strong> is developed</li>
<li>Passivity-based<ol>
<li>[11] M. Fujita, H. Kawai, and M. W. Spong, “<strong>Passivity-based</strong> dynamic visual feedback control for three-dimensional target tracking: Stability and l_{2}-gain performance analysis,” IEEE Transactions on Control Systems Technology, vol. 15, no. 1, pp. 40–52, 2007.</li>
<li>[12] T. Ibuki, T. Hatanaka, and M. Fujita, “<strong>Passivity-based</strong> visual pose regulation for a moving target object in three dimensions: Structure design and convergence analysis,” in Proc. IEEE Conf. Decis. Control. IEEE, 2012, pp. 5655–5660.</li>
</ol>
</li>
<li>unknown input observer approach<ol>
<li>[13] A. Dani, Z. Kan, N. Fischer, and W. E. Dixon, “Structure estimation of a moving object using a moving camera: An <strong>unknown input observer</strong> approach,” in Proc. IEEE Conf. Decis. Control, Orlando, FL, 2011, pp. 5005–5012.</li>
<li>[14] S. Jang, A. Dani, C. Crane, and W. E. Dixon, “Experimental results for moving object structure estimation using an <strong>unknown input observer</strong> approach,” in Proc. ASME Dyn. Syst. Control Conf., Fort Lauderdale, Florida, Oct. 2012.</li>
</ol>
</li>
<li>后来：<ol>
<li>[15] D. Chwa, A. Dani, H. Kim, and W. E. Dixon, “<strong>Camera motion estimation</strong> for 3-d structure reconstruction of moving objects,” in Proc. of the IEEE Int. Conf. on Systems, Man, and Cybernetics, 2012, pp. 1788–1793.</li>
<li>[16] D. Chwa, A. Dani, and W. E. Dixon, “<strong>Range and motion estimation</strong> of a monocular camera using static and moving objects,” IEEE Trans. Control Syst. Tech., vol. 24, no. 4, pp. 1174–1183, July 2016.</li>
</ol>
</li>
</ol>
</li>
<li>CL：concurrent learning (CL) which relaxes the assumption of PE<ol>
<li>[17] G. V. Chowdhary and E. N. Johnson, “Theory and ﬂight-test validation of a <strong>concurrent-learning adaptive controller</strong>,” J. Guid. Control Dynam., vol. 34, no. 2, pp. 592–607, Mar. 2011.</li>
<li>[18] G. Chowdhary, M. Mühlegg, J. How, and F. Holzapfel, “<strong>Concurrent learning</strong> adaptive model predictive control,” in Advances in Aerospace Guidance, Navigation and Control, Q. Chu, B. Mulder, D. Choukroun, E.-J. van Kampen, C. de Visser, and G. Looye, Eds. Springer Berlin Heidelberg, 2013, pp. 29–47.</li>
<li>[19] G. Chowdhary, T. Yucelen, M. Mühlegg, and E. N. Johnson, “<strong>Concurrent learning</strong> adaptive control of linear systems with exponentially convergent bounds,” Int. J. Adapt. Control Signal Process., vol. 27, no. 4, pp. 280–301, 2013.</li>
<li>[20] R. Kamalapurkar, P. Walters, and W. E. Dixon, “<strong>Concurrent learning</strong>-based approximate optimal regulation,” in Proc. IEEE Conf. Decis. Control, Florence, IT, Dec. 2013, pp. 6256–6261.</li>
</ol>
</li>
<li>2017：<ol>
<li>[5] Z. I. Bell, H.-Y. Chen, A. Parikh, and W. E. Dixon, “Single scene and path reconstruction with a monocular camera using integral concurrent learning,” in Proc. IEEE Conf. Decis. Control, 2017, pp. 3670–3675.</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>[21] J. Shi and C. Tomasi, “Good features to track,” in Proc. IEEE Conf.Comput. Vis. Pattern Recognit., 1994, pp. 593–600.</p>
<p>[22] B. Lucas and T. Kanade, “An iterative image registration technique with an application to stereo vision,” in Proc. Int. Joint Conf. Artif. Intell., 1981, pp. 674–679.</p>
<p>[23] G. Chowdhary and E. Johnson, “A singular value maximizing data recording algorithm for concurrent learning,” in Proc. Am. Control Conf., 2011, pp. 3547–3552.</p>
<p>[24] H. K. Khalil, Nonlinear Systems, 3rd ed. Upper Saddle River, NJ:Prentice Hall, 2002.Springer, 2004.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/03/04/c%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/mac_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E5%B0%8F%E8%B1%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/knowledge/%E7%9B%AE%E5%89%8D%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%93%B6%E9%A2%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/04/c%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/mac_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E5%B0%8F%E8%B1%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/knowledge/%E7%9B%AE%E5%89%8D%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%93%B6%E9%A2%88/" class="post-title-link" itemprop="url">目前在机器学习瓶颈</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-04 11:11:00" itemprop="dateCreated datePublished" datetime="2019-03-04T11:11:00+08:00">2019-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:41:52" itemprop="dateModified" datetime="2020-03-12T19:41:52+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/c%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-mac-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5-%E5%B0%8F%E8%B1%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-knowledge/" itemprop="url" rel="index">
                    <span itemprop="name">c数据科学/mac_机器学习/入门阶段/小象机器学习/knowledge</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/03/04/c%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/mac_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%A5%E9%97%A8%E9%98%B6%E6%AE%B5/%E5%B0%8F%E8%B1%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/knowledge/%E7%9B%AE%E5%89%8D%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%93%B6%E9%A2%88/" class="post-meta-item leancloud_visitors" data-flag-title="目前在机器学习瓶颈" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>177</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年3月4日 上午11:11</p>
<p>在上王泳的模式识别机器学习时，我发现：<strong>我对问题理解的不透彻</strong>，具体来说：</p>
<ol>
<li>我不能讲清楚一个知识的来源，以及他的中心思想。对于我来说，<strong>各个知识仅仅当成是一个名词来学习</strong>。</li>
<li>对于一个问题，我只知道要用什么方法解决，而<strong>为什么这个方法能解决</strong>，能解决到什么地步我都不清楚</li>
<li>这就导致我对这些知识没有一个本质的认识，最后知识零散的知识点，<strong>学完就忘</strong></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2017]SFM+PE+CL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2017%5DSFM+PE+CL/" class="post-title-link" itemprop="url">2017SFM+PE+CL</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-04 03:34:00" itemprop="dateCreated datePublished" datetime="2019-03-04T03:34:00+08:00">2019-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/03/04/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2017%5DSFM+PE+CL/" class="post-meta-item leancloud_visitors" data-flag-title="2017SFM+PE+CL" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年3月4日 下午3:34<br>Single Scene and Path Reconstruction with a Monocular Camera Using Integral Concurrent Learning</p>
<p>SFM的问题对象就是：<strong>depth information</strong></p>
<ol>
<li>estimate the structure of the scene（get <strong>depth information</strong>）<ol>
<li>利用：scale information<ol>
<li>multiple calibrated cameras may be used, for example, stereo vision, to <strong>recover the exact scale</strong> (cf., [1], [2])<ol>
<li>[1] R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision. Cambridge University Press, 2003.</li>
<li>[2] Y. Ma, S. Soatto, J. Kosecka, and S. Sastry, An Invitation to 3-D Vision.</li>
</ol>
</li>
</ol>
</li>
<li>利用<strong>motion</strong> (cf., [3]–[16]), such as, linear and angular velocities of the camera.<ol>
<li>Kalman ﬁlter (<strong>EKF</strong>) to estimate depth<ol>
<li>[3] S. Soatto, R. Frezza, and P. Perona, “Motion estimation via dynamic vision,” IEEE Trans. Autom. Control, vol. 41, no. 3, pp. 393–413, 1996.</li>
<li>[4] L. Matthies, T. Kanade, and R. Szeliski, “Kalman ﬁlter-based algorithm for estimating depth from image sequences,” Int. J. Comput. Vision, vol. 3, pp. 209–236, 1989.</li>
<li>[5] H. Kano, B. K. Ghosh, and H. Kanai, “Single camera based motion and shape estimation using extended Kalman ﬁltering,” Math. Comput. Modell., vol. 34, pp. 511–525, 2001.</li>
<li>[6] A. Chiuso, P. Favaro, H. Jin, and S. Soatto, “Structure from motion causally integrated over time,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 4, pp. 523–535, Apr. 2002.</li>
</ol>
</li>
<li><strong>exponential</strong>(快速、指数级) convergence of the structure estimate assuming a persistence of excitation (<strong>PE</strong>) condition is met<ol>
<li>[7] X. Chen and H. Kano, “State observer for a class of nonlinear systems and its application to machine vision,” IEEE Trans. Autom. Control, vol. 49, no. 11, pp. 2085–2091, 2004.</li>
<li>[14] A. De Luca, G. Oriolo, and P. Robuffo Giordano, “Feature depth observation for image-based visual servoing: Theory and experiments,” Int. J. Robot. Res., vol. 27, no. 10, pp. 1093–1116, 2008.</li>
<li>Extended Output Jacobian condition<ol>
<li>[15] F. Morbidi and D. Prattichizzo, “Range estimation from a moving camera: an immersion and invariance approach,” in Proc. IEEE Int. Conf. Robot. Autom., Kobe, Japan, May 2009, pp. 2810–2815.</li>
</ol>
</li>
<li>[16] A. Dani, N. Fischer, Z. Kan, and W. E. Dixon, “Globally exponentially stable observer for vision-based range estimation,” Mechatron., vol. 22, no. 4, pp. 381–389, Special Issue on Visual Servoing 2012.</li>
</ol>
</li>
<li>show <strong>asymptotic</strong>（渐进） convergence of the structure estimation errors<ol>
<li>[8] N. Zarrouati, E. Aldea, and P. Rouchon, “So(3)-invariant asymptotic observers for dense depth ﬁeld estimation based on visual data and known camera motion,” in Proc. Am. Control Conf., Fairmont Queen Elizabeth, Montreal, Canada, Jun. 2012, pp. 4116–4123.</li>
<li>[9] D. Braganza, D. M. Dawson, and T. Hughes, “Euclidean position estimation of static features using a moving camera with known velocities,” in Proc. IEEE Conf. Decis. Control, New Orleans, LA, USA, Dec. 2007, pp. 2695–2700.</li>
<li>[10] S. Gupta, D. Aiken, G. Hu, and W. E. Dixon, “Lyapunov-based range and motion identiﬁcation for a nonafﬁne perspective dynamic system,” in Proc. Am. Control Conf., Minneapolis, Minnesota, Jun. 2006, pp. 4471–4476.</li>
<li>[11] W. E. Dixon, Y. Fang, D. M. Dawson, and T. J. Flynn, “Range identiﬁcation for perspective vision systems,” IEEE Trans. Autom. Control, vol. 48, pp. 2232–2238, 2003.</li>
<li>[12] G. Hu, D. Aiken, S. Gupta, and W. Dixon, “Lyapunov-based range identiﬁcation for a paracatadioptric system,” IEEE Trans. Autom. Control, vol. 53, no. 7, pp. 1775–1781, 2008.</li>
<li>[13] D. Karagiannis and A. Astolﬁ, “A new solution to the problem of range identiﬁcation in perspective vision systems,” IEEE Trans. Autom. Control, vol. 50, no. 12, pp. 2074–2077, 2005.</li>
</ol>
</li>
</ol>
</li>
<li>SFM<ol>
<li>SFM的缺点：In SfM approaches, the potential for <strong>limited parallax</strong> still exists, but in many cases a camera may</li>
<li>两种方式去处理SFM的缺点：<ol>
<li><strong>online</strong> iterative methods<ol>
<li>定义：assume <strong>continuous measurements</strong> of the scene by <strong>the camera</strong></li>
<li><strong>[3]–[16]</strong></li>
<li>concurrent learning(CL)<ol>
<li>解释：relaxes the <strong>PE</strong> assumption</li>
<li><strong>[22]–[26]</strong></li>
<li>[22] G. V. Chowdhary and E. N. Johnson, “Theory and ﬂight-test validation of a concurrent-learning adaptive controller,” J. Guid. Control Dynam., vol. 34, no. 2, pp. 592–607, Mar. 2011.</li>
<li>[23] G. Chowdhary, M. Mühlegg, J. How, and F. Holzapfel, “Concurrent learning adaptive model predictive control,” in Advances in Aerospace Guidance, Navigation and Control, Q. Chu, B. Mulder, D. Choukroun, E.-J. van Kampen, C. de Visser, and G. Looye, Eds. Springer Berlin Heidelberg, 2013, pp. 29–47.</li>
<li>[24] G. Chowdhary, T. Yucelen, M. Mühlegg, and E. N. Johnson, “Concurrent learning adaptive control of linear systems with exponentially convergent bounds,” Int. J. Adapt. Control Signal Process., vol. 27, no. 4, pp. 280–301, 2013.Springer, 2004.</li>
<li>[25] R. Kamalapurkar, P. Walters, and W. E. Dixon, “Concurrent learningbased approximate optimal regulation,” in Proc. IEEE Conf. Decis. Control, Florence, IT, Dec. 2013, pp. 6256–6261.</li>
<li>[26] A. Parikh, R. Kamalapurkar, and W. E. Dixon. (2015) Integral concurrent learning: Adaptive control with parameter convergence without PE or state derivatives. arXiv:1512.03464.</li>
</ol>
</li>
</ol>
</li>
<li><strong>ofﬂine</strong> batch methods<ol>
<li>[1] R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision. Cambridge University Press, 2003.</li>
<li>[2] Y. Ma, S. Soatto, J. Kosecka, and S. Sastry, An Invitation to 3-D Vision.</li>
<li>[17] J. Oliensis, “A <strong>critique</strong> of structure-from-motion algorithms,” Comput.Vis. Image. Understand., vol. 80, pp. 172–214, 2000.</li>
<li>results do show <strong>convergence</strong><ol>
<li>[18] J. Oliensis and R. Hartley, “Iterative extensions of the strum/triggs algorithm: convergence and nonconvergence,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 12, pp. 2217–2233, 2007.</li>
<li>[19] F. Kahl and R. Hartley, “Multiple-view geometry under the L ∞ -norm,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 9, pp. 1603–1617, Sep. 2008.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>[20] K. Reif and R. Unbehauen, “The extended kalman ﬁlter as an exponential observer for nonlinear systems,” IEEE Trans. Signal Process., vol. 47, no. 8, pp. 2324–2328, 1999.</p>
<p>[21] M. Boutayeb, H. Rafaralahy, and M. Darouach, “Convergence analysis of the extended Kalman ﬁlter used as an observer for nonlinear deterministic discrete -time systems,” IEEE Trans. on Autom. Control, vol. 42, no. 4, pp. 581–586, 1997.</p>
<p>[27] Z. Bell, A. Parikh, J. Nezvadovitz, and W. E. Dixon, “Adaptive control of a surface marine craft with parameter identiﬁcation using integral concurrent learning,” in Proc. IEEE Conf. Decis. Contr., 2016.</p>
<p>[28] J. Shi and C. Tomasi, “Good features to track,” in Proc. IEEE Conf.Comput. Vis. Pattern Recognit., 1994, pp. 593–600.</p>
<p>[29] J.-Y. Bouguet, “Pyramidal implementation of the afﬁne lucas kanade feature tracker description of the algorithm,” Intel Corporation, vol. 5, no. 1-10, p. 4, 2001.</p>
<p>[30] B. Lucas and T. Kanade, “An iterative image registration technique with an application to stereo vision,” in Proc. Int. Joint Conf. Artif. Intell., 1981, pp. 674–679.</p>
<p>[31] G. Chowdhary and E. Johnson, “A singular value maximizing data recording algorithm for concurrent learning,” in Proc. American Control Conf., 2011, pp. 3547–3552.</p>
<p>[32] M. Krstic, I. Kanellakopoulos, and P. V. Kokotovic, Nonlinear and Adaptive Control Design. New York, NY, USA: John Wiley &amp; Sons, 1995.</p>
<p>[33] W. E. Dixon, A. Behal, D. M. Dawson, and S. Nagarkatti, Nonlinear Control of Engineering Systems: A Lyapunov-Based Approach. Birkhauser: Boston, 2003.</p>
<p>[34] H. K. Khalil, Nonlinear Systems, 3rd ed. Upper Saddle River, NJ:Prentice Hall, 2002.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/03/01/e%E8%A7%86%E8%A7%89%E7%9B%B8%E5%85%B3/czh_%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA(%E5%9B%BE%E7%89%87)/%E7%9F%A5%E8%AF%86%E7%82%B9/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A(%E5%86%99%E7%9A%84%E5%A5%BD)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/01/e%E8%A7%86%E8%A7%89%E7%9B%B8%E5%85%B3/czh_%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA(%E5%9B%BE%E7%89%87)/%E7%9F%A5%E8%AF%86%E7%82%B9/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A(%E5%86%99%E7%9A%84%E5%A5%BD)/" class="post-title-link" itemprop="url">相机标定(写的好)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-01 04:58:00" itemprop="dateCreated datePublished" datetime="2019-03-01T04:58:00+08:00">2019-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-01 15:27:51" itemprop="dateModified" datetime="2020-04-01T15:27:51+08:00">2020-04-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/e%E8%A7%86%E8%A7%89%E7%9B%B8%E5%85%B3-czh-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-%E5%9B%BE%E7%89%87-%E7%9F%A5%E8%AF%86%E7%82%B9/" itemprop="url" rel="index">
                    <span itemprop="name">e视觉相关/czh_三维重建(图片)/知识点#</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/03/01/e%E8%A7%86%E8%A7%89%E7%9B%B8%E5%85%B3/czh_%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA(%E5%9B%BE%E7%89%87)/%E7%9F%A5%E8%AF%86%E7%82%B9/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A(%E5%86%99%E7%9A%84%E5%A5%BD)/" class="post-meta-item leancloud_visitors" data-flag-title="相机标定(写的好)" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>39</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年3月1日 下午4:58</p>
<p><a href="http://zhaoxuhui.top/blog/2018/04/17/CameraCalibration.html" target="_blank" rel="noopener">相机畸变与标定</a><br>讲的特别好：<br><a href="https://www.zdaiot.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A/" target="_blank" rel="noopener">相机标定 | zdaiot</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2017]NRSFM+isometric%20SfT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2017%5DNRSFM+isometric%20SfT/" class="post-title-link" itemprop="url">2017NRSFM+isometric SfT</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-02-28 12:27:00" itemprop="dateCreated datePublished" datetime="2019-02-28T12:27:00+08:00">2019-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2017%5DNRSFM+isometric%20SfT/" class="post-meta-item leancloud_visitors" data-flag-title="2017NRSFM+isometric SfT" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年2月28日 下午12:27</p>
<p>[2017 PAMI]A Stable Analytical Framework for Isometric Shape-from-Template by Surface Integration</p>
<p>2019年2月28日 下午2:12</p>
<ol>
<li><p>这篇文章也就是在<strong>改进SFT</strong>，改进的方向是：</p>
<ol>
<li>大的噪点</li>
<li>object is small or viewed from larger distances</li>
<li>提出：ﬁrst-order quantities: the depth-gradient or the surface normal</li>
</ol>
</li>
<li><p>Non-Rigid Shape-from-Motion (<strong>NRSfM</strong>)</p>
<ol>
<li><strong>3.</strong>C. Bregler, A. Hertzmann, H. Biermann, “Recovering non-rigid 3D shape from image streams”,<em>Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.</em>, pp. 690-696, 2000.</li>
<li><strong>4.</strong>L. Torresani, A. Hertzmann, C. Bregler, “Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors”,<em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, vol. 30, no. 5, pp. 878-892, May 2008.</li>
<li><strong>5.</strong>A. Del Bue, “A factorization approach to structure from motion with shape priors”,<em>Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.</em>, pp. 1-8, 2008.</li>
<li><strong>6.</strong>J. Taylor, A. D. Jepson, K. N. Kutulakos, “Non-rigid structure from locally-rigid motion”,<em>Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.</em>, pp. 2761-2768, 2010.</li>
<li><strong>7.</strong>S. Vicente, L. Agapito, “Soft inextensibility constraints for template-free non-rigid reconstruction”,<em>Proc. 12th Eur. Conf. Computer Vision</em>, pp. 426-440, 2012.</li>
<li><strong>8.</strong>T. Collins, A. Bartoli, “Locally affine and planar deformable surface reconstruction from video”,<em>Proc. Int. Workshop Vis. Model. Vis.</em>, pp. 339-346, 2010.</li>
<li><strong>9.</strong>A. Chhatkuli, D. Pizarro, A. Bartoli, “Non-rigid shape-from-motion for isometric surfaces using infinitesimal planarity”,<em>Proc. Brit. Mach. Vision Conf.</em>, 2014.</li>
</ol>
</li>
<li><p><strong>isometric SfT(Shape-from-Template)</strong></p>
<ol>
<li>论文发展：<ol>
<li><strong>14.</strong>A. Bartoli, T. Collins, “Template-based isometric deformable 3D reconstruction with sampling-based focal length self-calibration”,<em>Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.</em>, pp. 1514-1521, 2013.</li>
<li><strong>18.</strong>F. Brunet, A. Bartoli, 照亮. Hartley, “Monocular template-based 3D surface reconstruction: Convex inextensible and nonconvex isometric methods”,<em>Comput. Vis. Image Understanding</em>, vol. 125, pp. 138-154, 2014.</li>
<li><strong>12.</strong>A. Bartoli, Y. Gérard, F. Chadebecq, T. Collins, D. Pizarro, “Shape-from-template”,<em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, vol. 37, no. 10, pp. 2099-2118, Oct. 2015.</li>
<li><strong>19.</strong>T. Collins, A. Bartoli, “Realtime shape-from-template: System and applications”,<em>Proc. IEEE Int. Symp. Mixed Augmented Reality</em>, pp. 116-119, 2015.</li>
</ol>
</li>
<li>relaxes isometry with <strong>inextensibility</strong>.Inextensibility means the distance between the neighboring points remain inferior to their geodesic distance in the template<ol>
<li>论文发展：<ol>
<li><strong>10.</strong>M. Perriollat, R. Hartley, A. Bartoli, “Monocular template-based reconstruction of inextensible surfaces”,<em>Int. J. Comput. Vis.</em>, vol. 95, no. 2, pp. 124-137, 2011.</li>
<li><strong>11.</strong> <em>M. Salzmann, P. Fua, “Linear local models for monocular reconstruction of deformable surfaces”,_IEEE Trans. Pattern Anal. Mach. Intell.</em>, vol. 33, no. 5, pp. 931-944, May 2011._</li>
<li><strong>13.</strong>T. D. Ngo, J. O. stlund, P. Fua, “Template-based monocular 3D shape recovery using Laplacian meshes”,<em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, vol. 38, no. 1, pp. 172-187, Jan. 2016.</li>
</ol>
</li>
</ol>
</li>
<li>解决问题：<ol>
<li><strong>registration</strong> between the template and image is solved using, for example, point correspondences </li>
<li><strong>remove outliers</strong> during registration[15],[16],[17]while <strong>small noise</strong> in correspondences has to be dealt with in the reconstruction step<ol>
<li><strong>15.</strong>J. Pilet, V. Lepetit, P. Fua, “Fast non-rigid surface detection registration and realistic augmentation”,<em>Int. J. Comput. Vis.</em>, vol. 76, no. 2, pp. 109-122, 2008.</li>
<li><strong>16.</strong>D. Pizarro, A. Bartoli, “Feature-based deformable surface detection with self-occlusion reasoning”,<em>Int. J. Comput. Vis.</em>, vol. 97, no. 1, pp. 54-70, 2012.</li>
<li><strong>17.</strong>T. Collins, A. Bartoli, “Using isometry to classify correct_incorrect 3D-2D correspondences”,_Proc. 13th Eur. Conf. Comput. Vision/, pp. 325-340, 2014.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="另一种分类："><a href="#另一种分类：" class="headerlink" title="另一种分类："></a>另一种分类：</h2><p>In order to organize the discussion on previous works in <strong>isometric SfT,</strong> we classify the methods based on their <em>final constraints and the way they are optimized</em>:</p>
<ol>
<li>_i)_zeroth-order methods based on inextensibility[11],[13],</li>
<li>_ii)_statistically optimal cost refinement[18],[19]and</li>
<li><em>iii)_analytical solutions from quadratic PDEs[12],[14]. The MDH-based methods in_i)</em>[10],[11]solve the SfT problem by maximizing depth while putting an upper bound on the distance between neighboring points.</li>
</ol>
<p><strong>1.</strong> R. I. Hartley, A. Zisserman, Multiple View Geometry in Computer Vision, Cambridge, U.K.:Cambridge Univ. Press, 2004.<br>Show Context <a href="https://doi.org/10.1017/CBO9780511811685" target="_blank" rel="noopener">CrossRef</a>  <a href="https://scholar.google.com/scholar?as_q=Multiple+View+Geometry+in+Computer+Vision&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>2.</strong>L. Maier-Hein, A. Groch, A. Bartoli, S. Bodenstedt, G. Boissonnat, P. Chang et al., “Comparative validation of single-shot optical techniques for laparoscopic 3D surface reconstruction”,<em>IEEE Trans. Med. Imag.</em>, vol. 33, no. 10, pp. 1913-1930, May 2014.<br> <a href="https://ieeexplore.ieee.org/document/6820756" target="_blank" rel="noopener">View Article</a>  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6820756" target="_blank" rel="noopener">Full Text: PDF </a> (1540KB) <a href="https://scholar.google.com/scholar?as_q=Comparative+validation+of+single-shot+optical+techniques+for+laparoscopic+3D%0A+surface+reconstruction&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a> </p>
<p><strong>20.</strong>T. Collins, P. Mesejo, A. Bartoli, “An analysis of errors in graph-based keypoint matching and proposed solutions”,<em>Proc. 13th Eur. Conf. Comput. Vision</em>, pp. 138-153, 2014.<br><strong>21.</strong>T. Collins, A. Bartoli, “Infinitesimal plane-based pose estimation”,<em>Int. J. Comput. Vis.</em>, vol. 109, no. 3, pp. 252-286, 2014.<br><strong>22.</strong>A. Chhatkuli, D. Pizarro, A. Bartoli, “Stable template-based isometric 3D reconstruction in all imaging conditions by linear least-squares”,<em>Proc. IEEE Conf. Comput. Vis. Pattern Recog.</em>, pp. 708-715, 2014.<br><strong>23.</strong>照亮. W. Sumner, J. Popović, “Deformation transfer for triangle meshes”,<em>ACM Trans. Graph.</em>, vol. 23, no. 3, pp. 399-405, 2004.<br><strong>24.</strong>O. Sorkine, D. Cohen-Or, Y. Lipman, M. Alexa, C. Rössl, H.-P. Seidel, “Laplacian surface editing”,<em>Proc. Eurographics_ACM SIGGRAPH Symp. Geom. Process./, pp. 175-184, 2004.<br><strong>25.</strong>A. Bartoli, D. Pizarro, T. Collins, “A robust analytical solution to isometric shape-from-template with focal length calibration”,_Proc. IEEE Int. Conf. Comput. Vision</em>, pp. 961-968, 2013.<br><strong>26.</strong>D. Pizarro, A. Bartoli, T. Collins, “Isowarp and conwarp: Warps that exactly comply with weak-perspective projection of deforming objects”,<em>Proc. Brit. Mach. Vision Conf.</em>, pp. 104.1-104.11, 2013.<br>Show Context <a href="https://doi.org/10.5244/C.27.104" target="_blank" rel="noopener">CrossRef</a>  <a href="https://scholar.google.com/scholar?as_q=Isowarp%0A+and+conwarp%3A+Warps+that+exactly+comply+with+weak-perspective+projection+of+deforming+objects&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>27.</strong>P. Dierckx, Curve Surface Fitting Splines, London, U.K.:Oxford Univ. Press, 1993.<br>Show Context <a href="https://scholar.google.com/scholar?as_q=Curve+Surface+Fitting+Splines&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>28.</strong>D. G. Lowe, “Distinctive image features from scale-invariant keypoints”,<em>Int. J. Comput. Vis.</em>, vol. 60, no. 2, pp. 91-110, 2004.<br>Show Context <a href="https://doi.org/10.1023/B:VISI.0000029664.99615.94" target="_blank" rel="noopener">CrossRef</a>  <a href="https://scholar.google.com/scholar?as_q=Distinctive+image+features+from+scale-invariant+keypoints%2C&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>29.</strong>P. F. Alcantarilla, A. Bartoli, A. J. Davison, “KAZE features”,<em>Proc. 12th Eur. Conf. Comput. Vis.</em>, pp. 214-227, 2012.<br>Show Context <a href="https://scholar.google.com/scholar?as_q=KAZE%0A+features&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>30.</strong>G. A. Puerto, G. L. Mariottini,<em>IEEE Trans. Med. Imag.</em>, vol. 32, no. 7, pp. 1201-1214, Jul. 2013.<br>Show Context <a href="https://ieeexplore.ieee.org/document/6410427" target="_blank" rel="noopener">View Article</a>  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6410427" target="_blank" rel="noopener">Full Text: PDF </a> (1989KB) <a href="https://scholar.google.com/scholar?as_q=IEEE+Trans.+Med.+Imag.&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>31.</strong>M. Perriollat, A. Bartoli, “A computational model of bounded developable surfaces with application to image-based three-dimensional reconstruction.”,<em>J. Vis. Comput. Animation</em>, vol. 24, no. 5, pp. 459-476, 2013.<br>Show Context <a href="https://doi.org/10.1002/cav.1478" target="_blank" rel="noopener">CrossRef</a>  <a href="https://scholar.google.com/scholar?as_q=A+computational+model+of+bounded+developable+surfaces+with+application+to+image-based%0A+three-dimensional+reconstruction.&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a><br><strong>32.</strong>A. Varol, M. Salzmann, P. Fua, 照亮. Urtasun, “A constrained latent variable model”,<em>Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.</em>, pp. 2248-2255, 2012.<br>Show Context <a href="https://scholar.google.com/scholar?as_q=A+constrained+latent+variable+model&as_occt=title&hl=en&as_sdt=0%2C31" target="_blank" rel="noopener">Google Scholar</a> </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2018]SFM+3Dshape(NRSFM)+isometric%20SfT+calibrated%20camera/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2018%5DSFM+3Dshape(NRSFM)+isometric%20SfT+calibrated%20camera/" class="post-title-link" itemprop="url">2018SFM+3Dshape(NRSFM)+isometric SfT+calibrated camera</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-02-28 09:53:00" itemprop="dateCreated datePublished" datetime="2019-02-28T09:53:00+08:00">2019-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2018%5DSFM+3Dshape(NRSFM)+isometric%20SfT+calibrated%20camera/" class="post-meta-item leancloud_visitors" data-flag-title="2018SFM+3Dshape(NRSFM)+isometric SfT+calibrated camera" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年2月28日 上午9:53</p>
<p>[2018]Incremental Non-Rigid Structure-from-Motion with Unknown Focal Length</p>
<p>2019年2月28日 下午2:12</p>
<ol>
<li><p>对<strong>SFT</strong>的改进，改进的方向是Unknown Focal Length</p>
</li>
<li><p>[1]. Longuet-Higgins, H.: A computer algorithm for <strong>reconstructing a scene</strong> from two projections.Nature 293 (1981) 133–135</p>
<ol>
<li>改进：<ol>
<li>[2]. Nist´er, D.: An efﬁcient solution to the ﬁve-point relative pose problem. IEEE Trans. Pattern Anal. Mach. Intell. 26(6) (2004) 756–777</li>
<li>[3]. Hartley, R.I., Zisserman, A.: Multiple View Geometry in Computer Vision. Second edn.Cambridge University Press, ISBN: 0521540518 (2004)</li>
</ol>
</li>
</ol>
</li>
<li><p>product：</p>
<ol>
<li>[4]. PhotoScan, A.: Agisoft PhotoScan User Manual Professional Edition, Version 1.2. (2017)</li>
<li>[5]. ReCap, A.: ReCap 360 – Advanced Workﬂows. (2015)</li>
</ol>
</li>
</ol>
<ol>
<li><p>[8]. Bregler, C., Hertzmann, A., Biermann, H.: Recovering non-rigid <strong>3D shape</strong> from image streams. In: CVPR. (2000)</p>
<ol>
<li>改进<ol>
<li>[9]. Torresani, L., Hertzmann, A., Bregler, C.: Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors. IEEE Trans. Pattern Anal. Mach. Intell. 30(5) (2008) 878–892</li>
<li>[10]. Del Bue, A.: A factorization approach to structure from motion with shape priors. In: CVPR.(2008)</li>
<li>[12]. Fayad, J., Agapito, L., Del Bue, A.: Piecewise quadratic reconstruction of non-rigid surfaces from monocular sequences. In: ECCV. (2010)</li>
<li>[14]. Taylor, J., Jepson, A.D., Kutulakos, K.N.: Non-rigid structure from locally-rigid motion. In:CVPR. (2010)</li>
<li><em>[7]. Dai, Y., Li, H., He, M.: A simple prior-free method for non-rigid structure-from-motion factorization. In: CVPR. (2012)</em></li>
<li>[11]. Garg, R., Roussos, A., Agapito, L.: Dense variational reconstruction of non-rigid surfaces from monocular video. In: CVPR. (2013)</li>
<li>[13]. Agudo, A., Montiel, J., Agapito, L., Calvo, B.: Online dense non-rigid 3d shape and camera motion recovery. In: BMVC. (2014)</li>
</ol>
</li>
</ol>
</li>
<li><p>SfT：评价： use of the <strong>isometric deformation prior</strong> with the perspective camera is considered to be the state-of-the-art</p>
<ol>
<li>[15]. Bartoli, A., Pizarro, D., Collins, T.: A robust analytical solution to isometric shape-fromtemplate with focal length calibration. In: ICCV. (2013)</li>
<li>[18]. Bartoli, A., Collins, T.: Template-based isometric deformable 3D reconstruction with sampling-based focal length self-calibration. In: CVPR. (2013)</li>
<li>[16]. Ngo, T.D., ¨Ostlund, J.O., Fua, P.: Template-based monocular 3D shape recovery using laplacian meshes. IEEE Transactions on Pattern Analysis and Machine Intelligence 38(1) (2016) 172–187</li>
<li>[17]. Chhatkuli, A., Pizarro, D., Bartoli, A., Collins, T.: A stable analytical framework for isometric shape-from-template by surface integration. IEEE Transactions on Pattern Analysis and Machine Intelligence 39(5) (2017) 833–850</li>
</ol>
</li>
</ol>
<ol>
<li>all of these methods discussed here require the <strong>calibrated camera</strong> for reconstruction and do not provide any insights on how they can be extended to an uncalibrated camera<ol>
<li><strong>NRSfM methods</strong> [6, 19, 25–27] also use <strong>isometry or inextensibility</strong> with the <strong>perspective camera model</strong><ol>
<li>[25]. Vicente, S., Agapito, L.: Soft inextensibility constraints for template-free non-rigid reconstruction. In: ECCV. (2012)</li>
<li>[26]. Chhatkuli, A., Pizarro, D., Bartoli, A.: Stable template-based isometric 3D reconstruction in all imaging conditions by linear least-squares. In: CVPR. (2014)</li>
<li>[27]. Parashar, S., Pizarro, D., Bartoli, A.: Isometric non-rigid shape-from-motion in linear time.In: CVPR. (2016)</li>
<li>[19]. Chhatkuli, A., Pizarro, D., Collins, T., Bartoli, A.: Inextensible non-rigid shape-from-motion by second-order cone programming. In: CVPR. (2016)</li>
<li><em>[6]. Ji, P., Li, H., Dai, Y., Reid, I.: ”Maximizing Rigidity” revisited: A convex programming approach for generic 3d shape reconstruction from multiple perspective views. In: ICCV. (2017)</em></li>
</ol>
</li>
<li>widely explored in the <strong>template-based methods</strong><ol>
<li>[20]. Perriollat, M., Hartley, R., Bartoli, A.: Monocular template-based reconstruction of inextensible surfaces. International Journal of Computer Vision 95(2) (2011) 124–137</li>
<li>[21]. Salzmann, M., Fua, P.: Linear local models for monocular reconstruction of deformable surfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence 33(5) (2011) 931–944</li>
<li>[24]. Bartoli, A., G´erard, Y., Chadebecq, F., Collins, T., Pizarro, D.: Shape-from-template. IEEE Trans. Pattern Anal. Mach. Intell. 37(10) (2015) 2099–2118</li>
</ol>
</li>
<li>use <strong>energy minimization</strong> approach on an initial solution also use the <strong>perspective camera model</strong> but with a <strong>piece-wise rigidity prior</strong><ol>
<li>[22]. Kumar, S., Dai, Y., Li, H.: Monocular dense 3d reconstruction of a complex dynamic scene from two perspective frames. In: ICCV. (2017)</li>
<li>[23]. Russell, C., Yu, R., Agapito, L.: Video pop-up: Monocular 3d reconstruction of dynamic scenes. In: ECCV. (2014)</li>
</ol>
</li>
</ol>
</li>
</ol>
<ol>
<li><p>[28]. Xiao, J., Kanade, T.: <strong>Uncalibrated</strong> perspective reconstruction of deformable structures. In:Tenth IEEE International Conference on Computer Vision (ICCV’05) Volume 1. Volume 2. (2005) 1075–1082 Vol. 2</p>
<ol>
<li>[29]. Salzmann, M., Hartley, R., Fua, P.: Convex optimization for deformable surface 3-D tracking.In: ICCV. (2007)</li>
<li>[30]. Akhter, I., Sheikh, Y., Khan, S., Kanade, T.: Trajectory space: A dual representation for nonrigid structure from motion. IEEE TPAMI 33(7) (2011) 1442–1456</li>
</ol>
</li>
<li><p>Nist´er, D.: Untwisting a projective reconstruction. International Journal of Computer Vision 60(2) (2004) 165–183</p>
</li>
<li><p>Chandraker, M., Agarwal, S., Kahl, F., Nist´er, D., Kriegman, D.: Autocalibration via rankconstrained estimation of the absolute quadric. In: Computer Vision and Pattern Recognition, 2007. CVPR’07. IEEE Conference on, IEEE (2007) 1–8</p>
</li>
<li><p>Dijkstra, E.W.: A note on two problems in connexion with graphs. Numer. Math. 1(1) (1959) 269–271</p>
</li>
<li><p>Varol, A., Salzmann, M., Fua, P., Urtasun, R.: A constrained latent variable model. In:CVPR. (2012)</p>
</li>
<li><p>Chhatkuli, A., Pizarro, D., Bartoli, A.: Non-rigid shape-from-motion for isometric surfaces using inﬁnitesimal planarity. In: BMVC. (2014)</p>
</li>
<li><p>White, R., Crane, K., Forsyth, D.: Capturing and animating occluded cloth. In: SIGGRAPH.(2007)</p>
</li>
<li><p>Sundaram, N., Brox, T., Keutzer, K.: Dense point trajectories by gpu-accelerated large displacement optical ﬂow. In: ECCV. (2010)</p>
</li>
<li><p>Innmann, M., Zollh¨ofer, M., Nießner, M., Theobalt, C., Stamminger, M. In: VolumeDeform:Real-Time Volumetric Non-rigid Reconstruction. Springer International Publishing, Cham (2016) 362–379</p>
</li>
<li><p>Gotardo, P.F., Martinez, A.M.: Computing smooth time trajectories for camera and deformable shape in structure from motion with occlusion. IEEE Trans. on Pattern Analysis and Machine Intelligence 33(10) (2011) 2051–2065</p>
</li>
<li><p>Chhatkuli, A., Pizarro, D., Collins, T., Bartoli, A.: Inextensible non-rigid structure-frommotion by second-order cone programming. IEEE Transactions on Pattern Analysis and Machine Intelligence PP(99) (2017) 1–1</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%E8%AE%BA%E6%96%87%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%E8%AE%BA%E6%96%87%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">论文索引</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-02-28 09:49:00" itemprop="dateCreated datePublished" datetime="2019-02-28T09:49:00+08:00">2019-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%E8%AE%BA%E6%96%87%E7%B4%A2%E5%BC%95/" class="post-meta-item leancloud_visitors" data-flag-title="论文索引" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>497</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年2月28日 上午9:49</p>
<p>2019年3月1日 上午11:21</p>
<ol>
<li>作为自己的<strong>论文索引库</strong>，这样就可以很快的查到<strong>关键点论文</strong>对我所<strong>查询论文</strong>的评价</li>
<li>这个库的关键是：找到<strong>关键点论文</strong>，通过它们来建立索引</li>
</ol>
<p>有以下几个问题需要注意：</p>
<ol>
<li>每篇文章为了体现自己的重要性，都会将原先的工作汇聚为一个大类，并且指出这个大类中的通病，进而引出自己的创新点。</li>
<li>在这个过程中，就会有意识的省略一些对自己没有好处的文章，也就是说：作者概括出来的这一大类并不是近几年的全部发展，只挑取了对自己有利的一部分。</li>
</ol>
<p>2019年4月4日 下午9:40<br><a href="bear://x-callback-url/open-note?id=77E9FE30-FE32-4A45-B9B3-2F7069D33D3A-2091-0001169F66E95C8F">NRSFM和trajectory reconstruction之间的区别</a></p>
<p><a href="bear://x-callback-url/open-note?id=7A9F0531-C9FA-45E3-AEC8-752BDD503491-1592-00016020C91BB222">[2017]SFM+PE+CL</a><br><a href="bear://x-callback-url/open-note?id=17F3D960-1DC7-4D56-8BF1-9570F5895399-1592-0000DBE2EC8C7597">[2015]Trajectory Triangulation+NRSFM</a>-清晰<br><a href="bear://x-callback-url/open-note?id=7C23C326-2437-4C45-B433-B31A9E94AB02-1592-0001559B3E4C01DE">[2018]SaMfM(trajectory triangulation)</a><br><a href="bear://x-callback-url/open-note?id=D7285937-DED9-47FA-B700-A38A7ADBB536-1592-0000BE8B7A736D46">[2010 ECCV]SFM+3D trajectory+NRSFM</a><br><a href="bear://x-callback-url/open-note?id=7F117E72-D06E-441F-9567-722DFE85B89E-1592-0000D4A628A1732F">[2017]NRSFM+isometric SfT</a><br><a href="bear://x-callback-url/open-note?id=547E3B25-E3F5-42D0-80DA-8CFD3E9BF738-1592-0000CB3DD291FB38">[2012 CVPR 戴玉超]NRSFM</a><br><a href="bear://x-callback-url/open-note?id=530DB846-E568-4BFD-ADA3-0DA894DA479C-1592-0000CCF56E61B917">[2018]SFM+3Dshape(NRSFM)+isometric SfT+calibrated camera</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/[2012%20CVPR%20%E6%88%B4%E7%8E%89%E8%B6%85]NRSFM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2012%20CVPR%20%E6%88%B4%E7%8E%89%E8%B6%85%5DNRSFM/" class="post-title-link" itemprop="url">2012 CVPR 戴玉超NRSFM</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-02-28 09:21:00" itemprop="dateCreated datePublished" datetime="2019-02-28T09:21:00+08:00">2019-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E8%AE%BA%E6%96%87-%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6-%E7%B4%A2%E5%BC%95/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_论文/视频求速度_索引</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/02/28/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E8%AE%BA%E6%96%87/%E8%A7%86%E9%A2%91%E6%B1%82%E9%80%9F%E5%BA%A6_%E7%B4%A2%E5%BC%95/%5B2012%20CVPR%20%E6%88%B4%E7%8E%89%E8%B6%85%5DNRSFM/" class="post-meta-item leancloud_visitors" data-flag-title="2012 CVPR 戴玉超NRSFM" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年2月28日 上午9:21</p>
<p> [2012 CVPR 戴玉超]A Simple Prior-free Method for Non-Rigid Structure-from-Motion Factorization</p>
<p>2019年2月28日 上午9:22</p>
<ol>
<li><p>这篇文章的牛逼之处在于：<strong>没有先验知识的约束了</strong>，这就是改进史上的一个重大突破</p>
</li>
<li><p>[7] C. Bregler, A. Hertzmann, and H. Biermann. Recovering non-rigid 3D shape from image streams. In CVPR, pages 690–696, 2000. 1, 2</p>
<ol>
<li>评价：<ol>
<li><strong>assuming</strong> that the nonrigid shape deformation follows a low-order linear combination model</li>
</ol>
</li>
<li>关键问题：该问题本身确实存在不适定或约束不足的问题，即仅基于正交正态性约束，无法唯一地恢复非刚性形状基及其对应的形状系数<ol>
<li>[26] J. Xiao, J.-x. Chai, and T. Kanade. A closed-form solution to non-rigid shape and motion recovery. In ECCV, pages 573–587, 2004. 1, 2, 3, 4, 6</li>
</ol>
</li>
<li>改进：introducing various <strong>prior knowledge</strong> to the problem at hand. They do so by assuming various constraints about the nonrigid scene, about the nonrigid shape bases, about the coefﬁcients, about the deformation, about the shape itself, or about the camera motion etc.<ol>
<li>[1] H. Aanæs and F. Kahl. Estimation of deformable structure and motion. In Workshop on Vision and Modelling of Dynamic Scenes, ECCV, pages 1–4, 2002. 2</li>
<li>[5] A. Bartoli, V. Gay-Bellile, U. Castellani, J. Peyras, S. Olsen, and P. Sayd. Coarse-to-ﬁne low-rank structure-from-motion. In CVPR, pages 1–8, 2008. 1, 2</li>
<li>[11] A. Del Bue. A factorization approach to structure from motion with shape priors. In CVPR, pages 1–8, 2008. 1, 2</li>
<li>[25] L. Torresani, A. Hertzmann, and C. Bregler. Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors. PAMI, 30, 2008. 1, 5, 6, 7</li>
<li>[3] I. Akhter, Y. Sheikh, S. Khan, and T. Kanade. Nonrigid structure from motion in trajectory space. In NIPS, 2008. 1, 2, 4, 5, 6, 8</li>
<li>[11] A. Del Bue. A factorization approach to structure from motion with shape priors. In CVPR, pages 1–8, 2008. 1, 2</li>
<li>[21] M. Paladini, A. D. Bue, M. Stosic, M. Dodig, J. Xavier, andL. Agapito. Factorization for non-rigid and articulated structure using metric projections. In CVPR, pages 2898–2905, 2009. 1, 5, 6</li>
<li>[22] V. Rabaud and S. Belongie. Linear embeddings in non-rigid structure from motion. In CVPR, pages 2427–2434, 2009. 2</li>
<li>[13] J. Fayad, L. Agapito, and A. Del Bue. Piecewise quadratic reconstruction of non-rigid surfaces from monocular sequences. In ECCV, pages 297–310, 2010. 2</li>
<li>[24] J. Taylor, A. D. Jepson, and K. N. Kutulakos. Non-rigid structure from locally-rigid motion. In CVPR, pages 27612768, 2010. 2</li>
<li>[14] P. Gotardo and A. Martinez. Computing smooth timetrajectories for camera and deformable shape in structure from motion with occlusion. PAMI, 33(10):2051–2065, 2011. 1, 2, 4, 5, 6</li>
</ol>
</li>
<li>改进：<ol>
<li>[2] I. Akhter, Y. Sheikh, and S. Khan. In defense of orthonormality constraints for nonrigid structure from motion. In CVPR, pages 1534–1541, 2009. 2, 4, 6</li>
<li>[16] R. Hartley and R. Vidal. Perspective nonrigid shape and motion recovery. In ECCV, pages 276–289, 2008. 2</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>[4] R. Angst, C. Zach, and M. Pollefeys. The generalized tracenorm and its application to structure-from-motion problems. In ICCV, pages 1–8, 2011. 3, 8</p>
<p>[6] M. Brand. A direct method for 3D factorization of nonrigid motion observed in 2D. In CVPR, 2005. 2, 4</p>
<p>[8] A. M. Buchanan and A. W. Fitzgibbon. Damped newton algorithms for matrix factorization with missing data. In CVPR, pages 316–322, 2005. 8</p>
<p>[9] E. Cand`es, X. Li, Y. Ma, and J. Wright. Robust principal component analysis. J. ACM, 58(3):11:1–37, 2011. 8</p>
<p>[10] Y. Dai, H. Li, and M. He. Element-wise factorization for n-view projective reconstruction. In ECCV, pages 396–409, 2010. 8</p>
<p>[12] A. Eriksson and A. van den Hengel. Efﬁcient computation of robust low-rank matrix approximations in the presence of missing data using the L 1 norm. In CVPR, pages 771–778, 2010. 8</p>
<p>[15] P. Gotardo and A. Martinez. Non-rigid structure from motion with complementary rank-3 spaces. In CVPR, pages 30653072, 2011. 6</p>
<p>[17] H. Li. Two-view motion segmentation from linear programming relaxation. In CVPR, pages 1 –8, june 2007. 8</p>
<p>[18] H. Li. Consensus set maximization with guaranteed global optimality for robust geometry estimation. In ICCV, pages 1074–1080. IEEE, 2009. 8</p>
<p>[19] G. Liu, Z. Lin, S. Yan, J. Sun, Y. Yu, and Y. Ma. Robust recovery of subspace structures by low-rank representation. CoRR, abs/1010.2955, 2010. 5</p>
<p>[20] S. Ma, D. Goldfarb, and L. Chen. Fixed point and bregman iterative methods for matrix rank minimization. Mathematical Programming, Series A, 128(1,2):321–353, 2011. 5</p>
<p>[23] B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimumrank solutions of linear matrix equations via nuclear norm minimization. SIAM Review, 52(3):471–501, 2010. 3</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenzhiheng.cn/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhiheng Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈志恒的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/" class="post-title-link" itemprop="url">文献阅读和文献综述</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-02-27 06:50:00" itemprop="dateCreated datePublished" datetime="2019-02-27T06:50:00+08:00">2019-02-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-12 19:58:03" itemprop="dateModified" datetime="2020-03-12T19:58:03+08:00">2020-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3-czh-%E7%A7%91%E7%A0%94-%E7%BB%8F%E9%AA%8C/" itemprop="url" rel="index">
                    <span itemprop="name">d科研相关/czh_科研/经验#</span>
                  </a>
                </span>
            </span>

          
            <span id="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/" class="post-meta-item leancloud_visitors" data-flag-title="文献阅读和文献综述" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>125</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>2019年2月27日 下午6:50</p>
<p>注：这篇文章中提到的方法都围绕一个目的：<strong>明确自己的问题</strong>，并且重新认识之后得到自己的<strong>知识体系框架</strong>。这里提到的方法都是为了教你达到这个目的。</p>
<h2 id="总流程："><a href="#总流程：" class="headerlink" title="总流程："></a>总流程：</h2><p><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/26AF6921-C737-4E97-9191-C86619A9A4DD.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/EF17D60A-457D-4626-81CF-CD67380DD195.png" alt></p>
<h2 id="文献阅读中要思考的问题："><a href="#文献阅读中要思考的问题：" class="headerlink" title="文献阅读中要思考的问题："></a>文献阅读中要思考的问题：</h2><p><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/C608C055-EEBA-48A2-BED9-2833FAC530B9.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/88359FF7-13E4-4659-852C-414CBE01D318.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/D0233ECC-6753-448B-A56F-CFDEAD871EC9.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/40DEC5A9-0A62-4249-83FC-10C8684ADBB3.png" alt></p>
<h2 id="写文献综述要思考的问题；"><a href="#写文献综述要思考的问题；" class="headerlink" title="写文献综述要思考的问题；"></a>写文献综述要思考的问题；</h2><p><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/12313754-B2A2-4CE0-9C4F-AAB32247C85B.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/C97265A6-7918-425F-8033-ECEB86825B7A.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/936B726C-5DEA-41BC-BCB4-90E3EB28B973.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/52F24B69-C392-4124-81E5-7D7BA39A5442.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/ACDA888E-B3AE-4BD9-B962-ADD52A10A6C9.png" alt></p>
<h2 id="文献综述的步骤和格式"><a href="#文献综述的步骤和格式" class="headerlink" title="文献综述的步骤和格式"></a>文献综述的步骤和格式</h2><p><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/3FA1D3DD-64F7-4678-89FB-33A343D6E523.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/D36ADE56-5C8F-4375-A2B8-8F36A81DD846.png" alt></p>
<h2 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h2><p><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/D84C7E51-C042-4C41-9925-9E34E46FABAB.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/C71272EB-48B2-4E42-BDEB-17DAB7C16842.png" alt><br><img src="/2019/02/27/d%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3/czh_%E7%A7%91%E7%A0%94/%E7%BB%8F%E9%AA%8C/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%92%8C%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/DBA3A2EB-118B-40A2-A800-218AD23A7A32.png" alt></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/46/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/46/">46</a><span class="page-number current">47</span><a class="page-number" href="/page/48/">48</a><span class="space">&hellip;</span><a class="page-number" href="/page/116/">116</a><a class="extend next" rel="next" href="/page/48/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhiheng Chen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">1157</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">103</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhiheng Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">1.1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">17:15</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        






  <script>
  function leancloudSelector(url) {
    url = encodeURI(url);
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.getAttribute('id'));
      var title = visitors.getAttribute('data-flag-title');

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.getAttribute('id'));
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=QiM1vjQ7SAoirKD4qY57L82O-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id'     : 'QiM1vjQ7SAoirKD4qY57L82O-gzGzoHsz',
            'X-LC-Key'    : 'aOHhzmfDblK0HGWUqEyb6ra2',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


</body>
</html>
